{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4727577",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wfdb\n",
    "import scipy\n",
    "import os\n",
    "import glob\n",
    "import subprocess\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c10db35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATA_ROOT = 'D:/ECG/processed/physionet2021'\n",
    "PHYSIONET_PATH = 'D:/ECG/physionet.org/files/challenge-2021/1.0.3/training'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "250c2ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "MANIFEST_PATH = f'{DATA_ROOT}/manifests'\n",
    "FINE_TUNE_MANIFEST = f'{MANIFEST_PATH}/cinc'\n",
    "MANIFEST_PATH_NOISE = f'{DATA_ROOT}/manifests_noise'\n",
    "FINE_TUNE_MANIFEST_NOISE = f'{MANIFEST_PATH_NOISE}/cinc'\n",
    "TOTAL_MANIFEST = f'{MANIFEST_PATH}/total/train.tsv'\n",
    "PRE_TRAINING_MANIFEST = f\"{MANIFEST_PATH}/cmsc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d56fb62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "FAIRSEQ_SIG_DIR = 'C:/Users/david/Documents/PythonScripts/fairseq-signals'\n",
    "CONVERT_TO_CLOCS_MANIFEST = f'{FAIRSEQ_SIG_DIR}/fairseq_signals/data/ecg/preprocess/convert_to_clocs_manifest.py'\n",
    "PRE_TRAINING_CONFIG = f'{FAIRSEQ_SIG_DIR}/examples/w2v_cmsc/config/pretraining'\n",
    "FINE_TUNING_CONFIG = f'{FAIRSEQ_SIG_DIR}/examples/w2v_cmsc/config/finetuning/ecg_transformer'\n",
    "FINE_TUNING_CONFIG_CMSC = f'{FAIRSEQ_SIG_DIR}/examples/w2v_cmsc/config/finetuning/ecg_transformer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "416d16a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "NOISE_DB = 'D:/ECG/physionet.org/files/nstdb/1.0.0'\n",
    "WEIGHTS_PATH = f'{PHYSIONET_PATH}/weights.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c036cd09",
   "metadata": {},
   "source": [
    "## Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d802aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df = pd.read_csv('dx_mapping_scored.csv', index_col='Dx')[['CPSC', 'CPSC_Extra', 'Chapman_Shaoxing', 'Georgia']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c1f248f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CPSC</th>\n",
       "      <th>CPSC_Extra</th>\n",
       "      <th>Chapman_Shaoxing</th>\n",
       "      <th>Georgia</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>atrial fibrillation</th>\n",
       "      <td>1221</td>\n",
       "      <td>153</td>\n",
       "      <td>1780</td>\n",
       "      <td>570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atrial flutter</th>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>445</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bundle branch block</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bradycardia</th>\n",
       "      <td>0</td>\n",
       "      <td>271</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>complete left bundle branch block</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>complete right bundle branch block</th>\n",
       "      <td>0</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1st degree av block</th>\n",
       "      <td>722</td>\n",
       "      <td>106</td>\n",
       "      <td>247</td>\n",
       "      <td>769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incomplete right bundle branch block</th>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>left axis deviation</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>382</td>\n",
       "      <td>940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>left anterior fascicular block</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>left bundle branch block</th>\n",
       "      <td>236</td>\n",
       "      <td>38</td>\n",
       "      <td>205</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low qrs voltages</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>249</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nonspecific intraventricular conduction disorder</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>235</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sinus rhythm</th>\n",
       "      <td>918</td>\n",
       "      <td>4</td>\n",
       "      <td>1826</td>\n",
       "      <td>1752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>premature atrial contraction</th>\n",
       "      <td>616</td>\n",
       "      <td>73</td>\n",
       "      <td>258</td>\n",
       "      <td>639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pacing rhythm</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poor R wave Progression</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>premature ventricular contractions</th>\n",
       "      <td>0</td>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prolonged pr interval</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prolonged qt interval</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>57</td>\n",
       "      <td>1391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwave abnormal</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right axis deviation</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>215</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right bundle branch block</th>\n",
       "      <td>1857</td>\n",
       "      <td>1</td>\n",
       "      <td>454</td>\n",
       "      <td>542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sinus arrhythmia</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sinus bradycardia</th>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>3889</td>\n",
       "      <td>1677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sinus tachycardia</th>\n",
       "      <td>0</td>\n",
       "      <td>303</td>\n",
       "      <td>1568</td>\n",
       "      <td>1261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>supraventricular premature beats</th>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t wave abnormal</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>1876</td>\n",
       "      <td>2306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t wave inversion</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>157</td>\n",
       "      <td>812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ventricular premature beats</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>294</td>\n",
       "      <td>357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  CPSC  CPSC_Extra  \\\n",
       "Dx                                                                   \n",
       "atrial fibrillation                               1221         153   \n",
       "atrial flutter                                       0          54   \n",
       "bundle branch block                                  0           0   \n",
       "bradycardia                                          0         271   \n",
       "complete left bundle branch block                    0           0   \n",
       "complete right bundle branch block                   0         113   \n",
       "1st degree av block                                722         106   \n",
       "incomplete right bundle branch block                 0          86   \n",
       "left axis deviation                                  0           0   \n",
       "left anterior fascicular block                       0           0   \n",
       "left bundle branch block                           236          38   \n",
       "low qrs voltages                                     0           0   \n",
       "nonspecific intraventricular conduction disorder     0           4   \n",
       "sinus rhythm                                       918           4   \n",
       "premature atrial contraction                       616          73   \n",
       "pacing rhythm                                        0           3   \n",
       "poor R wave Progression                              0           0   \n",
       "premature ventricular contractions                   0         188   \n",
       "prolonged pr interval                                0           0   \n",
       "prolonged qt interval                                0           4   \n",
       "qwave abnormal                                       0           1   \n",
       "right axis deviation                                 0           1   \n",
       "right bundle branch block                         1857           1   \n",
       "sinus arrhythmia                                     0          11   \n",
       "sinus bradycardia                                    0          45   \n",
       "sinus tachycardia                                    0         303   \n",
       "supraventricular premature beats                     0          53   \n",
       "t wave abnormal                                      0          22   \n",
       "t wave inversion                                     0           5   \n",
       "ventricular premature beats                          0           8   \n",
       "\n",
       "                                                  Chapman_Shaoxing  Georgia  \n",
       "Dx                                                                           \n",
       "atrial fibrillation                                           1780      570  \n",
       "atrial flutter                                                 445      186  \n",
       "bundle branch block                                              0      116  \n",
       "bradycardia                                                      0        6  \n",
       "complete left bundle branch block                                0        0  \n",
       "complete right bundle branch block                               0       28  \n",
       "1st degree av block                                            247      769  \n",
       "incomplete right bundle branch block                             0      407  \n",
       "left axis deviation                                            382      940  \n",
       "left anterior fascicular block                                   0      180  \n",
       "left bundle branch block                                       205      231  \n",
       "low qrs voltages                                               249      374  \n",
       "nonspecific intraventricular conduction disorder               235      203  \n",
       "sinus rhythm                                                  1826     1752  \n",
       "premature atrial contraction                                   258      639  \n",
       "pacing rhythm                                                    0        0  \n",
       "poor R wave Progression                                          0        0  \n",
       "premature ventricular contractions                               0        0  \n",
       "prolonged pr interval                                           12        0  \n",
       "prolonged qt interval                                           57     1391  \n",
       "qwave abnormal                                                 235      464  \n",
       "right axis deviation                                           215       83  \n",
       "right bundle branch block                                      454      542  \n",
       "sinus arrhythmia                                                 0      455  \n",
       "sinus bradycardia                                             3889     1677  \n",
       "sinus tachycardia                                             1568     1261  \n",
       "supraventricular premature beats                                 0        1  \n",
       "t wave abnormal                                               1876     2306  \n",
       "t wave inversion                                               157      812  \n",
       "ventricular premature beats                                    294      357  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10be6939",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a51656",
   "metadata": {},
   "source": [
    "Step 1: Take 10 second, 500 fs ECG WFDB data from select databases, split them into two 5 second data segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da10c200",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = f'python {FAIRSEQ_SIG_DIR}/fairseq_signals/data/ecg/preprocess/preprocess_physionet2021.py \\\n",
    "        {PHYSIONET_PATH} \\\n",
    "        --dest {DATA_ROOT} \\\n",
    "        --subset \"WFDB_Ga, WFDB_CPSC2018, WFDB_CPSC2018_2, WFDB_ChapmanShaoxing\"\\\n",
    "        --workers 1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54547547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "result = subprocess.run(cmd, stdout=subprocess.PIPE, shell=True)\n",
    "print(result.stdout.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f638cdc1",
   "metadata": {},
   "source": [
    "Step 2: Take processed ECG data and split them into pretraining and fine-tuning sets. In our case we use Georgia (Ga) as our fine tuning set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eed0f99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = f'python {FAIRSEQ_SIG_DIR}/fairseq_signals/data/ecg/preprocess/manifest.py \\\n",
    "        {DATA_ROOT} \\\n",
    "        --dest {MANIFEST_PATH} \\\n",
    "        --subset \"CPSC2018, CPSC2018_2, ChapmanShaoxing, Ga\" \\\n",
    "        --combine_subsets Ga'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a4785c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "result = subprocess.run(cmd, stdout=subprocess.PIPE, shell=True)\n",
    "print(result.stdout.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da496ea3",
   "metadata": {},
   "source": [
    "Step 3: For only the fine-tuning set, add noise from MIT-BIH stress db. Noise comes in 360fs, so resample to 500fs. Randomly sample 5 seconds noise segments, then add to the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "863397ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_noise(noise_path):\n",
    "    noise_dict = {}\n",
    "    for noise_type in ['bw', 'ma', 'em']:\n",
    "        samp = wfdb.rdsamp(f'{noise_path}/{noise_type}')\n",
    "        x = samp[0]\n",
    "        fs = samp[1]['fs']\n",
    "        resampled_noise = scipy.signal.resample(x, round(x.shape[0]*500/fs))\n",
    "        noise_dict[noise_type] = resampled_noise.T\n",
    "    return noise_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dbbe6e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(noise_dict, data_root):\n",
    "    for dataset in ['Ga']:\n",
    "        isExist = os.path.exists(f'{data_root}/{dataset}_noise')\n",
    "        if not isExist:\n",
    "            os.makedirs(f'{data_root}/{dataset}_noise')\n",
    "        for file in os.listdir(f'{data_root}/{dataset}'):\n",
    "            sample = scipy.io.loadmat(f'{DATA_ROOT}/{dataset}/{file}')\n",
    "            for noise_type in ['bw', 'ma', 'em']:\n",
    "                start_idx = random.randint(0, 902778-2501)\n",
    "                sampled_noise = noise_dict[noise_type][:, start_idx:start_idx+2500]\n",
    "                sample['feats'][:2,] = sample['feats'][:2,]+sampled_noise\n",
    "            scipy.io.savemat(f'{DATA_ROOT}/{dataset}_noise/{file}', sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c7f9e965",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_dict = generate_noise(NOISE_DB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2ada8e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_noise(noise_dict, DATA_ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d42429",
   "metadata": {},
   "source": [
    "Step 4: Repeat step 2 for the noisy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "63034074",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = f'python {FAIRSEQ_SIG_DIR}/fairseq_signals/data/ecg/preprocess/manifest.py \\\n",
    "        {DATA_ROOT} \\\n",
    "        --dest {MANIFEST_PATH_NOISE} \\\n",
    "        --subset \"Ga_noise\" \\\n",
    "        --combine_subsets Ga_noise'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b5fac674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "result = subprocess.run(cmd, stdout=subprocess.PIPE, shell=True)\n",
    "print(result.stdout.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe64cd4",
   "metadata": {},
   "source": [
    "## Pre-training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c797160",
   "metadata": {},
   "source": [
    "We will train two different pretraining models, w2v_cmsc_rlm, and w2v_cmsc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f99ee22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python C:/Users/david/Documents/PythonScripts/fairseq-signals/fairseq_signals/data/ecg/preprocess/convert_to_clocs_manifest.py             D:/ECG/processed/physionet2021/manifests/total/train.tsv             --dest D:/ECG/processed/physionet2021/manifests\n"
     ]
    }
   ],
   "source": [
    "cmd = f\"python {CONVERT_TO_CLOCS_MANIFEST} \\\n",
    "            {TOTAL_MANIFEST} \\\n",
    "            --dest {MANIFEST_PATH}\"\n",
    "print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f273f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "result = subprocess.run(cmd, stdout=subprocess.PIPE, shell=True)\n",
    "print(result.stdout.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7aa7f092",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = f\"fairseq-hydra-train \\\n",
    "            task.data={PRE_TRAINING_MANIFEST} \\\n",
    "            --config-dir {PRE_TRAINING_CONFIG} \\\n",
    "            --config-name w2v_cmsc_rlm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9160d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = subprocess.run(cmd, stdout=subprocess.PIPE, shell=True)\n",
    "print(result.stdout.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28413c01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a37e0e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = f\"fairseq-hydra-train \\\n",
    "            task.data={PRE_TRAINING_MANIFEST} \\\n",
    "            --config-dir {PRE_TRAINING_CONFIG} \\\n",
    "            --config-name w2v_cmsc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d561a991",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = subprocess.run(cmd, stdout=subprocess.PIPE, shell=True)\n",
    "print(result.stdout.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c57be8",
   "metadata": {},
   "source": [
    "## Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52d8b61",
   "metadata": {},
   "source": [
    "First, we will perform fine-tuning on the w2v_cmsc_rlm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "274ceff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRETRAIN_CHECKPOINT = f'C:/Users/david/Documents/PythonScripts/ECGPretraining/outputs/2023-04-22/11-42-07/checkpoints/checkpoint100.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e5c485",
   "metadata": {},
   "source": [
    "1. With first two leads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cb686e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = f\"fairseq-hydra-train \\\n",
    "        task.data={FINE_TUNE_MANIFEST} \\\n",
    "        model.model_path={PRETRAIN_CHECKPOINT} \\\n",
    "        --config-dir {FINE_TUNING_CONFIG} \\\n",
    "        --config-name diagnosis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab71cde5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = subprocess.run(cmd, stdout=subprocess.PIPE, shell=True)\n",
    "print(result.stdout.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c253ae63",
   "metadata": {},
   "source": [
    "2. With noisy first two leads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "746b46ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = f\"fairseq-hydra-train \\\n",
    "        task.data={FINE_TUNE_MANIFEST_NOISE} \\\n",
    "        model.model_path={PRETRAIN_CHECKPOINT} \\\n",
    "        --config-dir {FINE_TUNING_CONFIG} \\\n",
    "        --config-name diagnosis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1491580",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = subprocess.run(cmd, stdout=subprocess.PIPE, shell=True)\n",
    "print(result.stdout.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fa962c",
   "metadata": {},
   "source": [
    "Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abcb9655",
   "metadata": {},
   "outputs": [],
   "source": [
    "FINETUNE_CHECKPOINT = f'C:/Users/david/Documents/PythonScripts/ECGPretraining/outputs/2023-04-29/16-42-15/checkpoints/checkpoint_last.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "178ec102",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = f\"fairseq-hydra-validate \\\n",
    "        common_eval.path={FINETUNE_CHECKPOINT} \\\n",
    "        task.data={FINE_TUNE_MANIFEST} \\\n",
    "        model.model_path={PRETRAIN_CHECKPOINT} \\\n",
    "        --config-dir {FINE_TUNING_CONFIG} \\\n",
    "        --config-name diagnosis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b7f468c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-06 01:44:06,443][fairseq_cli.validate][INFO] - loading model from C:/Users/david/Documents/PythonScripts/ECGPretraining/outputs/2023-04-29/16-42-15/checkpoints/checkpoint_last.pt\r\n",
      "[2023-05-06 01:44:08,412][fairseq_signals.models.transformer][INFO] - Loaded pre-trained model parameters from C:/Users/david/Documents/PythonScripts/ECGPretraining/outputs/2023-04-22/11-42-07/checkpoints/checkpoint100.pt\r\n",
      "[2023-05-06 01:44:08,432][fairseq_signals.utils.checkpoint_utils][INFO] - Loaded a checkpoint in 1.99s\r\n",
      "[2023-05-06 01:44:08,433][fairseq_cli.validate][INFO] - num. shared model params: 62,041,754 (num. trained: 62,041,754)\r\n",
      "[2023-05-06 01:44:08,434][fairseq_cli.validate][INFO] - num. expert model params: 0 (num. trained: 0)\r\n",
      "[2023-05-06 01:44:08,583][fairseq_cli.validate][INFO] - {'_name': None,\r\n",
      " 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False},\r\n",
      " 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'json', 'log_file': None, 'wandb_project': None, 'wandb_entity': None, 'seed': 1, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'empty_cache_freq': 0, 'all_gather_list_size': 2048000, 'model_parallel_size': 1, 'profile': False, 'reset_logging': False, 'suppress_crashes': False},\r\n",
      " 'common_eval': {'_name': None, 'path': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None},\r\n",
      " 'criterion': {'_name': 'binary_cross_entropy_with_logits', 'weight': None, 'threshold': 0.5, 'report_auc': False, 'auc_average': 'macro', 'pos_weight': None, 'report_cinc_score': True, 'weights_file': 'D:/ECG/physionet.org/files/challenge-2021/1.0.3/training/weights.csv', 'multi_class_multi_label': False, 'per_log_keys': []},\r\n",
      " 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 128, 'required_batch_size_multiple': 8, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid,test', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 128, 'max_valid_steps': None, 'curriculum': 0, 'num_shards': 1, 'shard_id': 0},\r\n",
      " 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_rank': 0, 'disributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': 12355, 'device_id': 0, 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'fp16': False, 'memory_efficient_fp16': False},\r\n",
      " 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False},\r\n",
      " 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [5e-05]},\r\n",
      " 'model': {'_name': 'ecg_transformer_classifier', 'normalize': False, 'filter': False, 'data': 'D:/ECG/processed/physionet2021/manifests/cinc', 'args': None, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'layer_norm_first': False, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'extractor_mode': 'default', 'conv_feature_layers': '[(256, 2, 2)] * 4', 'in_d': 12, 'conv_bias': False, 'feature_grad_mult': 0.0, 'conv_pos': 128, 'conv_pos_groups': 16, 'model_path': 'C:/Users/david/Documents/PythonScripts/ECGPretraining/outputs/2023-04-22/11-42-07/checkpoints/checkpoint100.pt', 'no_pretrained_weights': False, 'freeze_finetune_updates': 0, 'final_dropout': 0.0, 'num_labels': 26},\r\n",
      " 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 320000, 'lr': [5e-05], 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'update_freq': [1], 'stop_min_lr': -1.0},\r\n",
      " 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'lr': [5e-05]},\r\n",
      " 'task': {'_name': 'ecg_classification', 'data': 'D:/ECG/processed/physionet2021/manifests/cinc', 'leads_to_load': \"['i', 'ii']\", 'leads_bucket': None, 'bucket_selection': 'uniform', 'sample_rate': None, 'filter': False, 'normalize': False, 'mean_path': None, 'std_path': None, 'enable_padding': True, 'enable_padding_leads': True, 'max_sample_size': None, 'min_sample_size': None, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'perturbation_mode': None, 'p': [1.0], 'max_amplitude': 0.1, 'min_amplitude': 0.0, 'dependency': True, 'shift_ratio': 0.2, 'num_segment': 1, 'max_freq': 0.2, 'min_freq': 0.01, 'k': 3, 'mask_leads_selection': 'random', 'mask_leads_prob': 0.5, 'mask_leads_condition': [4, 5], 'inferred_w2v_config': None, 'inferred_3kg_config': None, 'criterion_name': 'binary_cross_entropy_with_logits', 'model_name': None, 'clocs_mode': None, 'path_dataset': False, 'load_specific_lead': False}}\r\n",
      "[2023-05-06 01:44:09,198][fairseq_signals.data.ecg.raw_ecg_dataset][INFO] - loaded 2063, skipped 0 samples\r\n",
      "[2023-05-06 01:44:09,199][fairseq_cli.validate][INFO] - begin validation on valid subset\r\n",
      "[2023-05-06 01:44:36,072][valid][INFO] - {\"valid_loss\": \"4.455\", \"valid_nsignals\": \"2063\", \"valid_cinc_score\": \"0.577\", \"valid_accuracy\": \"0.04053\", \"valid_em_accuracy\": \"0.61852\", \"valid_partial_accuracy\": \"0.72235\", \"valid_precision\": \"1\", \"valid_recall\": \"0.69479\", \"valid_f1\": \"0.819913\"}\r\n",
      "[2023-05-06 01:44:36,090][fairseq_signals.data.ecg.raw_ecg_dataset][INFO] - loaded 2063, skipped 0 samples\r\n",
      "[2023-05-06 01:44:36,091][fairseq_cli.validate][INFO] - begin validation on test subset\r\n",
      "[2023-05-06 01:44:59,668][test][INFO] - {\"test_loss\": \"4.478\", \"test_nsignals\": \"2063\", \"test_cinc_score\": \"0.581\", \"test_accuracy\": \"0.04081\", \"test_em_accuracy\": \"0.63354\", \"test_partial_accuracy\": \"0.73018\", \"test_precision\": \"1\", \"test_recall\": \"0.70093\", \"test_f1\": \"0.824173\"}\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = subprocess.run(cmd, stdout=subprocess.PIPE, shell=True)\n",
    "print(result.stdout.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c45424",
   "metadata": {},
   "source": [
    "Next, do the same for w2v_cmsc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fc3f692",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRETRAIN_CHECKPOINT_CMSC = f'C:/Users/david/Documents/PythonScripts/ECGPretraining/outputs/2023-05-02/19-58-34/checkpoints/checkpoint_last.pt'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32facdf2",
   "metadata": {},
   "source": [
    "1. With first two leads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f645481",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = f\"fairseq-hydra-train \\\n",
    "        task.data={FINE_TUNE_MANIFEST} \\\n",
    "        model.model_path={PRETRAIN_CHECKPOINT_CMSC} \\\n",
    "        --config-dir {FINE_TUNING_CONFIG} \\\n",
    "        --config-name diagnosis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15a6691",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = subprocess.run(cmd, stdout=subprocess.PIPE, shell=True)\n",
    "print(result.stdout.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cb6e49",
   "metadata": {},
   "source": [
    "2. With noisy first two leads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08d5bfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = f\"fairseq-hydra-train \\\n",
    "        task.data={FINE_TUNE_MANIFEST_NOISE} \\\n",
    "        model.model_path={PRETRAIN_CHECKPOINT_CMSC} \\\n",
    "        --config-dir {FINE_TUNING_CONFIG} \\\n",
    "        --config-name diagnosis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb50fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = subprocess.run(cmd, stdout=subprocess.PIPE, shell=True)\n",
    "print(result.stdout.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71aceaca",
   "metadata": {},
   "source": [
    "## Classical classification for Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f11bedcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class ECGDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, manifest, data_root):\n",
    "        self.manifest = pd.read_table(manifest, header=None, skiprows=1)\n",
    "        self.data_root = data_root\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.manifest)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        file = self.manifest.iloc[index, 0]\n",
    "        ecg_data = scipy.io.loadmat(f\"{self.data_root}/{file}\")\n",
    "        return np.expand_dims(ecg_data['feats'], axis=0), ecg_data['label']\n",
    "        # return ecg_data['feats'], ecg_data['label']\n",
    "\n",
    "train_dataset = ECGDataset(TOTAL_MANIFEST, DATA_ROOT)\n",
    "val_dataset = ECGDataset(f'{FINE_TUNE_MANIFEST}/valid.tsv', DATA_ROOT)\n",
    "test_dataset = ECGDataset(f'{FINE_TUNE_MANIFEST}/test.tsv', DATA_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fee0253",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=64)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e195a41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33bbf5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e32aee80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv11): Conv2d(1, 64, kernel_size=(1, 32), stride=(1, 8))\n",
       "  (bn11): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu1): ReLU()\n",
       "  (conv12): Conv2d(64, 64, kernel_size=(1, 32), stride=(1, 8))\n",
       "  (bn12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv21): Conv2d(64, 128, kernel_size=(1, 32), stride=(2, 8))\n",
       "  (bn21): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu2): ReLU()\n",
       "  (conv22): Conv2d(128, 128, kernel_size=(1, 32), stride=(2, 8))\n",
       "  (bn22): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc1): Linear(in_features=128, out_features=26, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CNN(nn.Module):  \n",
    "    def __init__(self, num_labels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv11 = nn.Conv2d(1, 64, (1, 32), (1, 8))\n",
    "        self.bn11 = nn.BatchNorm2d(64)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv12 = nn.Conv2d(64, 64, (1, 32), (1, 8))\n",
    "        self.bn12 = nn.BatchNorm2d(64)\n",
    "\n",
    "\n",
    "\n",
    "        self.conv21 = nn.Conv2d(64, 128, (1, 32), (2, 8))\n",
    "        self.bn21 = nn.BatchNorm2d(128)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.conv22 = nn.Conv2d(128, 128, (1, 32), (2, 8))\n",
    "        self.bn22 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "        self.fc1 = nn.Linear(128, num_labels)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv11(x)\n",
    "        x = self.bn11(x)\n",
    "        x = self.relu1(x)\n",
    "        #x = self.conv12(x)\n",
    "        #x = self.bn12(x)\n",
    "        \n",
    "        x = self.conv21(x)\n",
    "        x = self.bn21(x)\n",
    "        x = self.relu2(x)\n",
    "        #x = self.conv22(x)\n",
    "        #x = self.bn22(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        out = self.fc1(x)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "\n",
    "model = CNN(num_labels=26)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a76859fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4131e28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resnet():\n",
    "    model = models.resnet18(weights=None)\n",
    "    #model = models.resnet50(weights=None)\n",
    "    model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "    model.fc = nn.Linear(512, 26)\n",
    "    #model.fc = nn.Linear(2048, 26)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5da884f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_resnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dbbc9dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=26, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8c770474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "924058"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "05d9ab79",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c71500e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "71886efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "770feee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4d75473f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv11): Conv2d(1, 64, kernel_size=(1, 32), stride=(1, 8))\n",
       "  (bn11): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu1): ReLU()\n",
       "  (conv12): Conv2d(64, 64, kernel_size=(1, 32), stride=(1, 8))\n",
       "  (bn12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv21): Conv2d(64, 128, kernel_size=(1, 32), stride=(2, 8))\n",
       "  (bn21): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu2): ReLU()\n",
       "  (conv22): Conv2d(128, 128, kernel_size=(1, 32), stride=(2, 8))\n",
       "  (bn22): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc1): Linear(in_features=128, out_features=26, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eed2bb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = pd.read_csv(WEIGHTS_PATH, index_col=0)\n",
    "weights = torch.from_numpy(weights.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "679f6f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mcm(labels, outputs):\n",
    "    num_recordings, num_classes = labels.size()\n",
    "    A = torch.zeros((num_classes, num_classes))\n",
    "\n",
    "    for i in range(num_recordings):\n",
    "        normalization = float(max(torch.sum(torch.any(torch.cat((labels[i, :].reshape(-1,1), outputs[i, :].reshape(-1,1)), dim=1), dim=0)), 1))\n",
    "        for j in range(num_classes):\n",
    "            if labels[i, j]:\n",
    "                for k in range(num_classes):\n",
    "                    if outputs[i, k]:\n",
    "                        A[j, k] += 1.0/normalization\n",
    "    return A\n",
    "\n",
    "def get_cinc_score(y_true, y_pred):\n",
    "    confusion_matrix = compute_mcm(y_true, y_pred)\n",
    "    observed_score = torch.nansum(confusion_matrix * weights)\n",
    "\n",
    "    confusion_matrix_correct = compute_mcm(y_true, y_true)\n",
    "    correct_score = torch.nansum(confusion_matrix_correct * weights)\n",
    "\n",
    "    sinus = torch.zeros(64, 26, dtype=torch.int32)\n",
    "    sinus[:,14] = 1\n",
    "    confusion_matrix_inactive = compute_mcm(y_true, sinus)\n",
    "    inactive_score = torch.nansum(confusion_matrix_inactive * weights)\n",
    "\n",
    "    #print(y_true, y_pred)\n",
    "    \n",
    "    #print(observed_score, inactive_score, correct_score)\n",
    "\n",
    "    if correct_score != inactive_score:\n",
    "        score = ((observed_score - inactive_score) / (correct_score - inactive_score))\n",
    "    else:\n",
    "        score = 0.0\n",
    "        \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c483d5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_table(table_file):\n",
    "    table = list()\n",
    "    with open(table_file, 'r') as f:\n",
    "        for i, l in enumerate(f):\n",
    "            arrs = [arr.strip() for arr in l.split(',')]\n",
    "            table.append(arrs)\n",
    "\n",
    "    num_rows = len(table)-1\n",
    "    if num_rows<1:\n",
    "        raise Exception('The table {} is empty.'.format(table_file))\n",
    "    row_lengths = set(len(table[i])-1 for i in range(num_rows))\n",
    "    if len(row_lengths)!=1:\n",
    "        raise Exception('The table {} has rows with different lengths.'.format(table_file))\n",
    "    num_cols = min(row_lengths)\n",
    "    if num_cols<1:\n",
    "        raise Exception('The table {} is empty.'.format(table_file))\n",
    "\n",
    "    # Find the row and column labels.\n",
    "    rows = [table[0][j+1] for j in range(num_rows)]\n",
    "    cols = [table[i+1][0] for i in range(num_cols)]\n",
    "\n",
    "    # Find the entries of the table.\n",
    "    values = np.zeros((num_rows, num_cols), dtype=np.float64)\n",
    "    for i in range(num_rows):\n",
    "        for j in range(num_cols):\n",
    "            value = table[i+1][j+1]\n",
    "            values[i, j] = float(value)\n",
    "\n",
    "    return rows, cols, values\n",
    "\n",
    "def load_weights(weight_file):\n",
    "    # Load the table with the weight matrix.\n",
    "    rows, cols, values = load_table(weight_file)\n",
    "\n",
    "    # Split the equivalent classes.\n",
    "    rows = [set(row.split('|')) for row in rows]\n",
    "    cols = [set(col.split('|')) for col in cols]\n",
    "    assert(rows == cols)\n",
    "\n",
    "    # Identify the classes and the weight matrix.\n",
    "    classes = rows\n",
    "    weights = values\n",
    "\n",
    "    return classes, weights\n",
    "\n",
    "def compute_modified_confusion_matrix(labels, outputs):\n",
    "    # Compute a binary multi-class, multi-label confusion matrix, where the rows\n",
    "    # are the labels and the columns are the outputs.\n",
    "    num_recordings, num_classes = np.shape(labels)\n",
    "    A = np.zeros((num_classes, num_classes))\n",
    "\n",
    "    # Iterate over all of the recordings.\n",
    "    for i in range(num_recordings):\n",
    "        # Calculate the number of positive labels and/or outputs.\n",
    "        normalization = float(max(np.sum(np.any((labels[i, :], outputs[i, :]), axis=0)), 1))\n",
    "        # Iterate over all of the classes.\n",
    "        for j in range(num_classes):\n",
    "            # Assign full and/or partial credit for each positive class.\n",
    "            if labels[i, j]:\n",
    "                for k in range(num_classes):\n",
    "                    if outputs[i, k]:\n",
    "                        A[j, k] += 1.0/normalization\n",
    "\n",
    "    return A\n",
    "\n",
    "def compute_challenge_metric(weights, labels, outputs, classes, sinus_rhythm={'426783006'}):\n",
    "    num_recordings, num_classes = np.shape(labels)\n",
    "    if sinus_rhythm in classes:\n",
    "        sinus_rhythm_index = classes.index(sinus_rhythm)\n",
    "    else:\n",
    "        raise ValueError('The sinus rhythm class is not available.')\n",
    "\n",
    "    # Compute the observed score.\n",
    "    A = compute_modified_confusion_matrix(labels, outputs)\n",
    "    observed_score = np.nansum(weights * A)\n",
    "\n",
    "    # Compute the score for the model that always chooses the correct label(s).\n",
    "    correct_outputs = labels\n",
    "    A = compute_modified_confusion_matrix(labels, correct_outputs)\n",
    "    correct_score = np.nansum(weights * A)\n",
    "\n",
    "    # Compute the score for the model that always chooses the sinus rhythm class.\n",
    "    inactive_outputs = np.zeros((num_recordings, num_classes), dtype=np.bool_)\n",
    "    inactive_outputs[:, sinus_rhythm_index] = 1\n",
    "    A = compute_modified_confusion_matrix(labels, inactive_outputs)\n",
    "    inactive_score = np.nansum(weights * A)\n",
    "\n",
    "    if correct_score != inactive_score:\n",
    "        normalized_score = float(observed_score - inactive_score) / float(correct_score - inactive_score)\n",
    "    else:\n",
    "        normalized_score = 0.0\n",
    "\n",
    "    return normalized_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e852c946",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes, weights = load_weights(WEIGHTS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e4ce6f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.classification import MultilabelAUROC\n",
    "\n",
    "def eval_model(model, val_loader):\n",
    "    model.eval()\n",
    "    y_pred = torch.LongTensor()\n",
    "    y_score = torch.Tensor()\n",
    "    y_true = torch.IntTensor()\n",
    "    for data, target in val_loader:\n",
    "        data, target = data.to(device, dtype=torch.float), target.to(device, dtype=torch.float)\n",
    "        y_hat = torch.sigmoid(model(data))\n",
    "        \n",
    "        y_score = torch.cat((y_score, y_hat.detach().to('cpu')), dim=0)\n",
    "        y_hat = (y_hat > 0.2).int().detach().to('cpu')\n",
    "        target = target.detach().to('cpu').type(torch.int32)\n",
    "        \n",
    "        y_pred = torch.cat((y_pred, y_hat), dim=0)\n",
    "        y_true = torch.cat((y_true, torch.squeeze(target, 1)), dim=0)\n",
    "        \n",
    "    auroc = MultilabelAUROC(num_labels=26, average=\"macro\", thresholds=5)\n",
    "    roc_auc = auroc(y_score, torch.squeeze(y_true, 1))\n",
    "    print(torch.sum(y_pred))\n",
    "    cinc_score = compute_challenge_metric(weights, y_true.numpy(), y_pred.numpy(), classes)\n",
    "\n",
    "    return roc_auc, cinc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8d821917",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_dataloader, val_dataloader, n_epoch, optimizer, criterion): \n",
    "    for epoch in range(n_epoch):\n",
    "        model.train()\n",
    "        curr_epoch_loss = []\n",
    "        CinC_history = []\n",
    "        for data, target in tqdm(train_dataloader):\n",
    "            data, target = data.to(device, dtype=torch.float), target.to(device, dtype=torch.float)\n",
    "\n",
    "            y_hat = model(data)\n",
    "            loss = criterion(y_hat, torch.squeeze(target, 1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            curr_epoch_loss.append(loss.cpu().data.numpy())\n",
    "            \n",
    "        print(f\"Epoch {epoch}: curr_epoch_loss={np.mean(curr_epoch_loss)}\")\n",
    "        roc_auc, cinc_score = eval_model(model, val_dataloader)\n",
    "        print(f\"Epoch {epoch}: val_roc: {roc_auc}, CinC_score: {cinc_score}\")\n",
    "        CinC_history.append(cinc_score)\n",
    "        if cinc_score >= np.max(CinC_history):\n",
    "            torch.save(model.state_dict(), 'cnn.pt')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b0085d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1e535991",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 579/579 [04:26<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: curr_epoch_loss=0.24435146152973175\n",
      "tensor(5715)\n",
      "Epoch 0: val_roc: 0.42860907316207886, CinC_score: 0.1887297693045686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 579/579 [03:45<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: curr_epoch_loss=0.20071753859519958\n",
      "tensor(5203)\n",
      "Epoch 1: val_roc: 0.4293023645877838, CinC_score: 0.15989659876194268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 579/579 [03:51<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: curr_epoch_loss=0.19508537650108337\n",
      "tensor(5620)\n",
      "Epoch 2: val_roc: 0.43475356698036194, CinC_score: 0.20327349343744922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 579/579 [03:50<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: curr_epoch_loss=0.18268758058547974\n",
      "tensor(3735)\n",
      "Epoch 3: val_roc: 0.4481239914894104, CinC_score: 0.12049196241736619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 579/579 [03:59<00:00,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: curr_epoch_loss=0.17641134560108185\n",
      "tensor(4376)\n",
      "Epoch 4: val_roc: 0.4330042600631714, CinC_score: 0.14364325481988385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 579/579 [04:00<00:00,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: curr_epoch_loss=0.17509521543979645\n",
      "tensor(4770)\n",
      "Epoch 5: val_roc: 0.4398568272590637, CinC_score: 0.15391858633293212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 579/579 [03:52<00:00,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: curr_epoch_loss=0.17308813333511353\n",
      "tensor(2727)\n",
      "Epoch 6: val_roc: 0.4412396550178528, CinC_score: 0.03850513117394164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 579/579 [03:32<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: curr_epoch_loss=0.17100264132022858\n",
      "tensor(4156)\n",
      "Epoch 7: val_roc: 0.44665002822875977, CinC_score: 0.186642833956303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 579/579 [03:42<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: curr_epoch_loss=0.16902294754981995\n",
      "tensor(3818)\n",
      "Epoch 8: val_roc: 0.4473414123058319, CinC_score: 0.17553322968289853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 579/579 [03:52<00:00,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: curr_epoch_loss=0.16772276163101196\n",
      "tensor(3383)\n",
      "Epoch 9: val_roc: 0.4565739333629608, CinC_score: 0.16875891449870645\n"
     ]
    }
   ],
   "source": [
    "model = train_model(model, train_dataloader, val_dataloader, 10, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7233a391",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'cnn.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d1d118af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv11): Conv2d(1, 64, kernel_size=(1, 32), stride=(1, 8))\n",
       "  (bn11): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu1): ReLU()\n",
       "  (conv12): Conv2d(64, 64, kernel_size=(1, 32), stride=(1, 8))\n",
       "  (bn12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv21): Conv2d(64, 128, kernel_size=(1, 32), stride=(2, 8))\n",
       "  (bn21): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu2): ReLU()\n",
       "  (conv22): Conv2d(128, 128, kernel_size=(1, 32), stride=(2, 8))\n",
       "  (bn22): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc1): Linear(in_features=128, out_features=26, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('cnn.pt'))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "03c0deb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3376)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.4733), 0.14517453885142168)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cdcbcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
